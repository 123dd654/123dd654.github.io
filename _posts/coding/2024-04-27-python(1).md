---
layout: post
title: python(1)
date: 2024-04-27 14:54 +0900
description: python
image: https://github.com/123dd654/123dd654.github.io/assets/161431124/87b99b95-f93c-4a9c-a357-39d7b6ce6b26
category: 2024년도 공부내용
tags: python requests beautifulsoup4 lxml pandas selenium driver
published: true
sitemap: true
---

<h4>안녕하세요!🫶<br/>
오늘은 python을 활용하여 애플뮤직사이트의 차트를 불러오는 방법에 대해 알아보겠습니다.</h4>

### 먼저 python을 시작하기 전 필수로 설치해야하는 파일에 대해 말씀드리겠습니다 😉

- python 설치
  본인에게 맞는 윈도우나 맥용 python을 설치해주셔야 합니다.
  추가적으로 vscode에서 python을 설치하면 pylance, python Debugger이 자동적으로 설치됩니다.

<br />

- requsets 설치
  각 패키지들을 설치합니다
  아래에는 역할들을 간단하게 정리해보았습니다.

```javascript
requests: HTTP 요청을 보내고 응답을 받아오는 라이브러리로, 웹 페이지의 HTML 내용을 가져올 때 사용합니다.
beautifulsoup4: HTML 및 XML 문서를 파싱하고 검색하는 데 사용되는 라이브러리로, 웹 스크래핑할 때 HTML 요소를 추출하는 데 도움이 됩니다.
lxml: 파이썬용 XML 및 HTML 처리 라이브러리로, BeautifulSoup과 함께 사용하여 HTML을 파싱하고 처리하는 데 사용됩니다.
pandas: 데이터 분석 및 조작을 위한 라이브러리로, 테이블 형식의 데이터를 다룰 때 효과적입니다.
selenium: 웹 애플리케이션 테스트 자동화를 위한 라이브러리로, 웹 브라우저를 제어하고 다양한 동작을 자동화하는 데 사용됩니다.
webdrivermanager : Selenium 웹 드라이버의 설치 및 관리를 자동화하는 도구입니다. 이를 통해 개발자는 웹 드라이버의 버전 및 설정을 명시적으로 관리하지 않아도 됩니다.
```

- driver 설치
  본인에게 맞는 윈도우나 맥용 python을 설치해주셔야 합니다.
  https://chromedriver.chromium.org/downloads 다운로드 사이트 남겨드립니다.

### 코드를 하나씩 보며 설명드리겠습니다. 😉

- 필요한 라이브러리 가져오기

```javascript
from selenium import webdriver                                              # 웹 자동화를 위한 Selenium 라이브러리를 가져옵니다.
from selenium.webdriver.chrome.service import Service as ChromeService      # Chrome 웹 드라이버 서비스를 제어하기 위한 클래스를 가져옵니다.
from selenium.webdriver.chrome.options import Options as ChromeOptions      # Chrome 브라우저 옵션을 설정하기 위한 클래스를 가져옵니다.
from webdriver_manager.chrome import ChromeDriverManager                    # Chrome 웹 드라이버를 자동으로 설치하고 관리하는 ChromeDriverManager 클래스를 가져옵니다.
from selenium.webdriver.common.by import By                                 # 웹 요소를 찾기 위한 방법을 제공하는 By 클래스를 가져옵니다.
from selenium.webdriver.support.ui import WebDriverWait                     # 웹 페이지가 로드될 때까지 기다리기 위한 WebDriverWait 클래스를 가져옵니다.
from selenium.webdriver.support import expected_conditions as EC            # 특정 조건이 충족될 때까지 기다리기 위한 expected_conditions 클래스를 가져옵니다.
from bs4 import BeautifulSoup                                               # HTML을 파싱하기 위한 BeautifulSoup 라이브러리를 가져옵니다.
from datetime import datetime                                               # 날짜와 시간 데이터를 처리하기 위한 datetime 라이브러리를 가져옵니다.
import time                                                                 # 시간을 다루기 위한 time 라이브러리를 가져옵니다.
import json                                                                 # JSON 파일을 다루기 위한 json 라이브러리를 가져옵니다.
```

이 코드는 웹 자동화와 HTML 파싱을 위한 라이브러리들을 가져옵니다.
Selenium은 웹 브라우저를 제어하고, BeautifulSoup은 HTML을 파싱합니다.
또한 날짜와 시간을 처리하기 위한 datetime과 JSON 파일을 다루기 위한 json 라이브러리도 가져옵니다.

<br />

- 현재 날짜 가져오기

```javascript
current_date = datetime.now().strftime("%Y-%m-%d")
filename = f"chart_apple100_{current_date}.json"
```

이 부분은 현재 날짜를 가져와서 JSON 파일의 이름을 설정하는 부분입니다.
datetime.now().strftime("%Y-%m-%d")는 현재 날짜를 년-월-일 형식으로 문자열로 변환합니다.
그리고 그 값을 이용하여 filename 변수에 "chart*apple100*" 뒤에 현재 날짜를 붙여서 JSON 파일의 이름을 설정합니다.
이렇게 함으로써 매일 새로운 파일을 생성하여 데이터를 저장할 수 있습니다.

<br />

- 웹 드라이버 설정

```javascript
options = ChromeOptions()                                                   # Chrome 브라우저 설정을 위한 객체를 생성합니다.
service = ChromeService(executable_path=ChromeDriverManager().install())    # Chrome 웹 드라이버 서비스를 설정합니다.
```

여기서는 Chrome 브라우저의 옵션을 설정하고, Chrome 웹 드라이버의 서비스를 설정하는 부분입니다.
ChromeOptions()는 Chrome 브라우저의 옵션을 설정하기 위한 객체를 생성합니다.
ChromeService(executable_path=ChromeDriverManager().install())는 Chrome 웹 드라이버의 서비스를 설정합니다.
ChromeDriverManager().install()는 Chrome 드라이버의 경로를 설정하고, 필요시 자동으로 설치합니다.
이를 통해 운영체제에 맞는 Chrome 드라이버를 자동으로 다운로드하고 설정합니다.

<br />

- 웹 드라이버 설정(2)

```javascript
browser = webdriver.Chrome((service = service), (options = options));
```

이 코드는 Chrome 브라우저를 제어하기 위한 웹 드라이버를 설정합니다.
webdriver.Chrome()은 Chrome 브라우저를 제어하기 위한 WebDriver 객체를 생성합니다.
이때, service와 options 매개변수를 전달하여 Chrome 웹 드라이버 서비스와 옵션을 설정합니다.
이렇게 함으로써 Selenium이 Chrome 브라우저를 제어할 수 있게 됩니다.

<br />

- Chrome 브라우저 해당 URL로 이동

```javascript
browser.get(
  "https://music.apple.com/kr/playlist/%EC%98%A4%EB%8A%98%EC%9D%98-top-100-%EB%8C%80%ED%95%9C%EB%AF%BC%EA%B5%AD/pl.d3d10c32fbc540b38e266367dc8cb00c"
);
```

이 부분은 Selenium을 사용하여 Chrome 브라우저를 해당 URL로 이동시키는 역할을 합니다.
browser.get() 메서드를 사용하여 주어진 URL에 해당하는 웹 페이지로 이동합니다.
이 코드에서는 Apple Music에서 한국의 상위 100곡을 담은 플레이리스트 페이지로 이동합니다.

<br />

- 페이지가 완전히 로드될 때까지 대기

```javascript
WebDriverWait(browser, 10).until(
  EC.presence_of_element_located((By.CLASS_NAME, "songs-list"))
);
```

이 부분은 페이지가 완전히 로드될 때까지 기다리는 역할을 합니다. WebDriverWait 객체를 사용하여 최대 10초간 기다립니다.
EC.presence_of_element_located((By.CLASS_NAME, "songs-list"))는 "songs-list" 클래스 이름을 가진 요소가 페이지에 나타날 때까지 기다립니다.
이를 통해 페이지의 로딩이 완료될 때까지 기다립니다.

<br />

- 업데이트된 페이지 소스를 변수에 저장

```javascript
html_source_updated = browser.page_source;
soup = BeautifulSoup(html_source_updated, "html.parser");
```

이 코드는 웹 페이지의 업데이트된 소스코드를 가져와 BeautifulSoup을 사용하여 파싱하는 부분입니다.
browser.page_source는 Selenium을 사용하여 브라우저에 표시된 현재 페이지의 소스코드를 가져옵니다.
그리고 이를 BeautifulSoup으로 파싱하여 변수 soup에 저장합니다. 이렇게 하면 파싱된 HTML 소스를 분석하여 필요한 정보를 추출할 수 있습니다.

<br />

- 노래정보 추출

```javascript
song_data = []
songs_list = soup.find_all('div', class_='songs-list-row', role='row')

for song in songs_list:
```

이 부분은 추출한 HTML에서 각 노래의 정보를 추출하는 부분입니다.
BeautifulSoup의 find_all() 메서드를 사용하여 HTML에서 div 태그 중 class가 'songs-list-row'이고 role이 'row'인 요소들을 모두 찾습니다.
이후 for 루프를 통해 각 노래의 정보를 추출합니다. 이 부분은 아래의 코드에서 설명을 이어나갈게요.

<br />

- 각 메서드를 이용해서 요소 찾기

```javascript
ranking = song.find("div", (class_ = "songs-list-row__rank")).text.strip();
title = song.find("div", (class_ = "songs-list-row__song-name")).text.strip();
artist = song.find("a", { "data-testid": "click-action" }).text.strip();
album = song.find_all("a", { "data-testid": "click-action" })[1].text.strip();
img_tag = song.find("picture").find("source", (type = "image/webp"));
```

이 부분은 각 노래에서 순위, 제목, 아티스트, 앨범, 이미지 URL을 추출하는 부분입니다.
BeautifulSoup의 find() 및 find_all() 메서드를 사용하여 각 요소를 찾습니다.
ranking, title, artist, album 변수에는 각각 노래의 순위, 제목, 아티스트, 앨범 정보가 저장되며, img_tag 변수에는 노래의 이미지를 나타내는 HTML 태그가 저장됩니다.

<br />

- 이미지 URL 추출

```javascript
    if img_tag:
        image_sources = img_tag['srcset']
        image_url = next((src.split(' ')[0] for src in image_sources.split(',') if '80x80bb.webp' in src), "No image available")
    else:
        image_url = "No image available"
```

이 부분은 노래의 이미지 URL을 추출하는 부분입니다.
img_tag 변수에 이미지 태그가 존재하는 경우,srcset 속성에서 이미지의 URL을 추출합니다.
이미지의 크기가 80x80인 경우에 해당하는 URL을 찾아 image_url 변수에 저장합니다.
만약 이미지 태그가 없는 경우, "No image available" 문자열을 image_url 변수에 저장합니다.
이렇게 하면 각 노래의 이미지 URL을 추출할 수 있습니다.

<br />

- 각 노래의 정보를 data에 추가

```javascript
song_data.append({
  ranking: ranking,
  title: title,
  artist: artist,
  album: album,
  image_url: image_url,
});
```

이 부분은 각 노래의 정보를 song_data 리스트에 추가하는 부분입니다.
ranking, title, artist, album, image_url 변수에 저장된 각각의 정보를 딕셔너리 형태로 구성하여 song_data 리스트에 추가합니다.
이렇게 하면 모든 노래의 정보가 song_data 리스트에 저장되게 됩니다.

<br />

- 추출된 데이터를 JSON 파일로 저장

```javascript
with open(filename, 'w', encoding='utf-8') as f:
    json.dump(song_data, f, ensure_ascii=False, indent=4)
```

이 부분은 추출한 노래 데이터를 JSON 파일로 저장하는 부분입니다.
filename 변수에 지정된 파일 이름으로 JSON 파일을 열고, 추출한 노래 데이터를 해당 파일에 저장합니다.
json.dump() 함수를 사용하여 song_data 리스트를 JSON 형식으로 변환하고, 이를 파일에 작성합니다.
ensure_ascii=False 옵션을 사용하여 유니코드 문자를 인코딩하지 않도록 설정하고, indent=4 옵션을 사용하여 들여쓰기를 추가하여 가독성을 높입니다.

<br />

- 브라우저 종료

```javascript
browser.quit();
```

마지막으로, 이 코드는 웹 브라우저를 종료하는 부분입니다.
Selenium을 사용하여 웹 브라우저를 제어할 때는 작업이 완료되면 반드시 웹 브라우저를 종료해야 합니다.
browser.quit() 메서드를 호출하여 현재 열려 있는 모든 창과 세션을 닫습니다.
이렇게 하면 웹 브라우저 자원을 해제하고 메모리를 확보할 수 있습니다.

### 전체적인 코드를 보여드리겠습니다 이대로만 입력하시면 불러오기가 가능합니다. 😉

```javascript
from selenium import webdriver
from selenium.webdriver.chrome.service import Service as ChromeService
from selenium.webdriver.chrome.options import Options as ChromeOptions
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from bs4 import BeautifulSoup
from datetime import datetime
import time
import json

# 현재 날짜 가져오기
current_date = datetime.now().strftime("%Y-%m-%d")
filename = f"chart_apple100_{current_date}.json"

# 웹 드라이브 설치
options = ChromeOptions()
service = ChromeService(executable_path=ChromeDriverManager().install())
browser = webdriver.Chrome(service=service, options=options)
browser.get("https://music.apple.com/kr/playlist/%EC%98%A4%EB%8A%98%EC%9D%98-top-100-%EB%8C%80%ED%95%9C%EB%AF%BC%EA%B5%AD/pl.d3d10c32fbc540b38e266367dc8cb00c")

# 페이지가 완전히 로드될 때까지 대기
WebDriverWait(browser, 10).until(
    EC.presence_of_element_located((By.CLASS_NAME, "songs-list"))
)

# 업데이트된 페이지 소스를 변수에 저장
html_source_updated = browser.page_source
soup = BeautifulSoup(html_source_updated, 'html.parser')

# 노래 정보를 추출
song_data = []
songs_list = soup.find_all('div', class_='songs-list-row', role='row')

for song in songs_list:
    ranking = song.find('div', class_='songs-list-row__rank').text.strip()
    title = song.find('div', class_='songs-list-row__song-name').text.strip()
    artist = song.find('a', {'data-testid': 'click-action'}).text.strip()
    album = song.find_all('a', {'data-testid': 'click-action'})[1].text.strip()
    img_tag = song.find('picture').find('source', type="image/webp")  # More specific targeting to webp images
    if img_tag:
        image_sources = img_tag['srcset']
        # Extracting the desired 80x80 webp image URL from srcset
        image_url = next((src.split(' ')[0] for src in image_sources.split(',') if '80x80bb.webp' in src), "No image available")
    else:
        image_url = "No image available"

    song_data.append({
        'ranking': ranking,
        'title': title,
        'artist': artist,
        'album': album,
        'image_url': image_url
    })

# 추출된 데이터를 JSON 파일로 저장
with open(filename, 'w', encoding='utf-8') as f:
    json.dump(song_data, f, ensure_ascii=False, indent=4)

# 브라우저 종료
browser.quit()
```

여기까지 python을 이용하여 음악리스트를 불러오는법에 대해 알아봤습니다.
도움이 되셨길 바라며 이만 마치겠습니다.
고생하셨습니다.🫶😊
